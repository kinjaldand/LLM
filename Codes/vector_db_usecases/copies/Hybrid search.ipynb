{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f440ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f86e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pinecone_text.sparse import BM25Encoder\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from DLAIUtils import Utils\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600cb42b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m utils \u001b[38;5;241m=\u001b[39m \u001b[43mUtils\u001b[49m()\n\u001b[0;32m      2\u001b[0m PINECONE_API_KEY \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mget_pinecone_api_key()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Utils' is not defined"
     ]
    }
   ],
   "source": [
    "utils = Utils()\n",
    "PINECONE_API_KEY = utils.get_pinecone_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd65df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "utils = Utils()\n",
    "INDEX_NAME = utils.create_dlai_index_name('dl-ai')\n",
    "\n",
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
    "  pinecone.delete_index(INDEX_NAME)\n",
    "pinecone.create_index(\n",
    "  INDEX_NAME,\n",
    "  dimension=512,\n",
    "  metric=\"dotproduct\",\n",
    "  spec=ServerlessSpec(cloud='aws', region='us-west-2')\n",
    ")\n",
    "index = pinecone.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = load_dataset(\n",
    "    \"ashraq/fashion-product-images-small\",\n",
    "    split=\"train\"\n",
    ")\n",
    "fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24fb417",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = fashion['image']\n",
    "metadata = fashion.remove_columns('image')\n",
    "images[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.to_pandas()\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeace1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Encoder()\n",
    "bm25.fit(metadata['productDisplayName'])\n",
    "metadata['productDisplayName'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb07489f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bm25' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbm25\u001b[49m\u001b[38;5;241m.\u001b[39mencode_queries(metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproductDisplayName\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      2\u001b[0m bm25\u001b[38;5;241m.\u001b[39mencode_documents(metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproductDisplayName\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bm25' is not defined"
     ]
    }
   ],
   "source": [
    "bm25.encode_queries(metadata['productDisplayName'][0])\n",
    "bm25.encode_documents(metadata['productDisplayName'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21598b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/clip-ViT-B-32', \n",
    "    device=device)\n",
    "model\n",
    "dense_vec = model.encode([metadata['productDisplayName'][0]])\n",
    "dense_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fcb0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "fashion_data_num = 1000\n",
    "\n",
    "for i in tqdm(range(0, min(fashion_data_num,len(fashion)), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(fashion))\n",
    "    # extract metadata batch\n",
    "    meta_batch = metadata.iloc[i:i_end]\n",
    "    meta_dict = meta_batch.to_dict(orient=\"records\")\n",
    "    # concatinate all metadata field except for id and year to form a single string\n",
    "    meta_batch = [\" \".join(x) for x in meta_batch.loc[:, ~meta_batch.columns.isin(['id', 'year'])].values.tolist()]\n",
    "    # extract image batch\n",
    "    img_batch = images[i:i_end]\n",
    "    # create sparse BM25 vectors\n",
    "    sparse_embeds = bm25.encode_documents([text for text in meta_batch])\n",
    "    # create dense vectors\n",
    "    dense_embeds = model.encode(img_batch).tolist()\n",
    "    # create unique IDs\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "\n",
    "    upserts = []\n",
    "    # loop through the data and create dictionaries for uploading documents to pinecone index\n",
    "    for _id, sparse, dense, meta in zip(ids, sparse_embeds, dense_embeds, meta_dict):\n",
    "        upserts.append({\n",
    "            'id': _id,\n",
    "            'sparse_values': sparse,\n",
    "            'values': dense,\n",
    "            'metadata': meta\n",
    "        })\n",
    "    # upload the documents to the new hybrid index\n",
    "    index.upsert(upserts)\n",
    "\n",
    "# show index description after uploading the documents\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fef8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"dark blue french connection jeans for men\"\n",
    "\n",
    "sparse = bm25.encode_queries(query)\n",
    "dense = model.encode(query).tolist()\n",
    "\n",
    "result = index.query(\n",
    "    top_k=14,\n",
    "    vector=dense,\n",
    "    sparse_vector=sparse,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "from io import BytesIO\n",
    "from base64 import b64encode\n",
    "\n",
    "# function to display product images\n",
    "def display_result(image_batch):\n",
    "    figures = []\n",
    "    for img in image_batch:\n",
    "        b = BytesIO()\n",
    "        img.save(b, format='png')\n",
    "        figures.append(f'''\n",
    "            <figure style=\"margin: 5px !important;\">\n",
    "              <img src=\"data:image/png;base64,{b64encode(b.getvalue()).decode('utf-8')}\" style=\"width: 90px; height: 120px\" >\n",
    "            </figure>\n",
    "        ''')\n",
    "    return HTML(data=f'''\n",
    "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
    "        {''.join(figures)}\n",
    "        </div>\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da6b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_result(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c014ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_scale(dense, sparse, alpha: float):\n",
    "    \"\"\"Hybrid vector scaling using a convex combination\n",
    "\n",
    "    alpha * dense + (1 - alpha) * sparse\n",
    "\n",
    "    Args:\n",
    "        dense: Array of floats representing\n",
    "        sparse: a dict of `indices` and `values`\n",
    "        alpha: float between 0 and 1 where 0 == sparse only\n",
    "               and 1 == dense only\n",
    "    \"\"\"\n",
    "    if alpha < 0 or alpha > 1:\n",
    "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "    # scale sparse and dense vectors to create hybrid search vecs\n",
    "    hsparse = {\n",
    "        'indices': sparse['indices'],\n",
    "        'values':  [v * (1 - alpha) for v in sparse['values']]\n",
    "    }\n",
    "    hdense = [v * alpha for v in dense]\n",
    "    return hdense, hsparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ff07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"dark blue french connection jeans for men\"\n",
    "#Closer to 0==more sparse, closer to 1==more dense\n",
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=1)\n",
    "result = index.query(\n",
    "    top_k=6,\n",
    "    vector=hdense,\n",
    "    sparse_vector=hsparse,\n",
    "    include_metadata=True\n",
    ")\n",
    "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
    "display_result(imgs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee890c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in result[\"matches\"]:\n",
    "    print(x[\"metadata\"]['productDisplayName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195dd2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"dark blue french connection jeans for men\"\n",
    "#Closer to 0==more sparse, closer to 1==more dense\n",
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0)\n",
    "result = index.query(\n",
    "    top_k=6,\n",
    "    vector=hdense,\n",
    "    sparse_vector=hsparse,\n",
    "    include_metadata=True\n",
    ")\n",
    "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
    "display_result(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0987f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in result[\"matches\"]:\n",
    "    print(x[\"metadata\"]['productDisplayName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ca385",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"dark blue french connection jeans for men\"\n",
    "#Closer to 0==more sparse, closer to 1==more dense\n",
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=1)\n",
    "result = index.query(\n",
    "    top_k=6,\n",
    "    vector=hdense,\n",
    "    sparse_vector=hsparse,\n",
    "    include_metadata=True\n",
    ")\n",
    "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
    "display_result(imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3704c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in result[\"matches\"]:\n",
    "    print(x[\"metadata\"]['productDisplayName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab8dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e384bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector_db_env2",
   "language": "python",
   "name": "vector_db_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
